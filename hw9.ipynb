{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fashin MNIST\n",
    "MNIST 패션 이미지를 CNN을 이용하여 분류하세요. CNN을 이용한 분류 결과를 MLP와 비교해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras import models \n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "from keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Multi-Layer Perceptron (MLP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "y_train=to_categorical(y_train)\n",
    "y_test=to_categorical(y_test)\n",
    "\n",
    "# preprocessing\n",
    "X_train = X_train.reshape((60000, 28*28))\n",
    "X_train = X_train/255\n",
    "\n",
    "X_test = X_test.reshape((10000, 28*28))\n",
    "X_test = X_test/255\n",
    "\n",
    "net = models.Sequential()\n",
    "net.add(layers.Dense(512, activation='relu', input_shape=(28*28,))) \n",
    "net.add(layers.Dense(512, activation='relu')) \n",
    "net.add(layers.Dropout(0.5))\n",
    "net.add(layers.Dense(512, activation='relu')) \n",
    "net.add(layers.Dropout(0.5))\n",
    "net.add(layers.Dense(10, activation='softmax')) \n",
    "net.compile(optimizer='nadam',loss='categorical_crossentropy',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_train[:10000]\n",
    "partial_X_train = X_train[10000:]\n",
    "\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 23s 455us/step - loss: 0.5774 - acc: 0.7944 - val_loss: 0.5283 - val_acc: 0.8216\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 22s 438us/step - loss: 0.4239 - acc: 0.8502 - val_loss: 0.4197 - val_acc: 0.8441\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 22s 433us/step - loss: 0.3863 - acc: 0.8623 - val_loss: 0.3628 - val_acc: 0.8691\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 22s 439us/step - loss: 0.3590 - acc: 0.8713 - val_loss: 0.3880 - val_acc: 0.8561\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 22s 439us/step - loss: 0.3528 - acc: 0.8730 - val_loss: 0.3468 - val_acc: 0.8777\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 22s 431us/step - loss: 0.3385 - acc: 0.8798 - val_loss: 0.4266 - val_acc: 0.8441\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 23s 459us/step - loss: 0.3276 - acc: 0.8821 - val_loss: 0.3291 - val_acc: 0.8806\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 23s 458us/step - loss: 0.3244 - acc: 0.8857 - val_loss: 0.3493 - val_acc: 0.8732\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 26s 529us/step - loss: 0.3129 - acc: 0.8896 - val_loss: 0.3614 - val_acc: 0.8720\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 25s 495us/step - loss: 0.3101 - acc: 0.8902 - val_loss: 0.3532 - val_acc: 0.8739\n"
     ]
    }
   ],
   "source": [
    "val= net.fit(partial_X_train,partial_y_train,epochs=10, batch_size=64, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 146us/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = net.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,y_train),(X_test,y_test)=fashion_mnist.load_data()\n",
    "\n",
    "X_train=X_train.reshape((60000,28,28,1))\n",
    "X_train=X_train/255\n",
    "\n",
    "X_test=X_test.reshape((10000,28,28,1))\n",
    "X_test=X_test/255\n",
    "\n",
    "y_train=to_categorical(y_train)\n",
    "y_test=to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = models.Sequential()\n",
    "net.add(layers.Conv2D(32,(3,3), activation='relu', input_shape=(28,28,1)))\n",
    "net.add(layers.MaxPooling2D((2,2)))\n",
    "net.add(layers.Conv2D(64,(3,3), activation='relu')) \n",
    "net.add(layers.MaxPooling2D((2,2)))\n",
    "net.add(layers.Conv2D(64,(3,3), activation='relu'))\n",
    "net.add(layers.Flatten())\n",
    "net.add(layers.Dense(100, activation='relu')) \n",
    "net.add(layers.Dense(10, activation='softmax')) \n",
    "net.compile(optimizer='nadam',loss='categorical_crossentropy',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               57700     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 114,454\n",
      "Trainable params: 114,454\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 44s 733us/step - loss: 0.1835 - acc: 0.9305\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 44s 733us/step - loss: 0.1659 - acc: 0.9369\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 44s 731us/step - loss: 0.1541 - acc: 0.9420\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 45s 754us/step - loss: 0.1418 - acc: 0.9463\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 45s 743us/step - loss: 0.1309 - acc: 0.9499 ETA: 1s - loss: 0.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x28d2da34ef0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(X_train, y_train, epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 237us/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = net.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
